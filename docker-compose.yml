version: '3.8'
services:
  frontend:
    build: 
      context: ./frontend
    container_name: react-frontend
    ports:
      - "3000:3000"
    volumes:
      - ./frontend:/app
      - /app/node_modules
    environment:
      - CHOKIDAR_USEPOLLING=true
    command: npm start
    depends_on:
      - backend
  node-dev:
    image: node:22
    command: bash
    volumes:
      - ./frontend:/app
    tty: true

  # FastAPI
  backend:
    build:
      context: ./backend
    container_name: fastapi-backend
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
    volumes:
      - ./backend:/app
    ports:
      - "8000:8000"
    environment:
      - DB_HOST=fastapi-db
      - DB_PORT=5432
      - DB_NAME=fastapi
      - DB_USER=fastapi
      - DB_PASSWORD=12345
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
    env_file:
      - .env.fastapi
    depends_on:
      - fastapi-db
      - kafka

  # Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"

  # Kafka
  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:29093
      KAFKA_LISTENERS: PLAINTEXT://kafka:29092,CONTROLLER://kafka:29093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      
  consumer:
    build:
      context: ./backend
    container_name: kafka-consumer
    command: python app/kafka_consumer.py
    volumes:
      - ./backend:/app
    environment:
      - DB_HOST=fastapi-db
      - DB_PORT=5432
      - DB_NAME=fastapi
      - DB_USER=fastapi
      - DB_PASSWORD=12345
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
    depends_on:
      - fastapi-db
      - kafka

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8081:8080"
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:29092
      - KAFKA_CLUSTERS_0_ZOOKEEPER=zookeeper:2181
    depends_on:
      - kafka
      - zookeeper

  # PostgreSQL for FastAPI
  fastapi-db:
    image: postgres:15
    environment:
      POSTGRES_DB: fastapi
      POSTGRES_USER: fastapi
      POSTGRES_PASSWORD: 12345
    volumes:
      - fastapi_postgres_data:/var/lib/postgresql/data
    ports:
      - "5434:5432"

  # PostgreSQL for Airflow
  airflow-db:
    image: postgres:15
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: 12345
      POSTGRES_DB: airflow
    volumes:
      - airflow_postgres_data:/var/lib/postgresql/data
    ports:
      - "5433:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 5s
      retries: 5

  # Redis
  redis:
    image: redis:latest
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 30s
      retries: 50

  # Airflow Init
  airflow-init:
    image: apache/airflow:2.8.1
    depends_on:
      - airflow-db
      - redis
    environment:
      - PYTHONPATH=/opt/airflow
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:12345@airflow-db/airflow
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:12345@airflow-db/airflow
      - AIRFLOW__CELERY__BROKER_URL=redis://:@redis:6379/0
      - _AIRFLOW_DB_UPGRADE=true
      - _AIRFLOW_WWW_USER_CREATE=true
      - _AIRFLOW_WWW_USER_USERNAME=airflow
      - _AIRFLOW_WWW_USER_PASSWORD=12345
    env_file:
      - .env
      - .env.aws
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/scripts:/opt/airflow/scripts
      - ./airflow/utils:/opt/airflow/utils
      - ./dummy:/opt/airflow/dummy
    command: version

  # Airflow Webserver
  airflow-webserver:
    image: apache/airflow:2.8.1
    depends_on:
      - airflow-init
    ports:
      - "8080:8080"
    environment:
      - PYTHONPATH=/opt/airflow
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:12345@airflow-db/airflow
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:12345@airflow-db/airflow
      - AIRFLOW__CELERY__BROKER_URL=redis://:@redis:6379/0
      - _AIRFLOW_WWW_USER_USERNAME=airflow
      - _AIRFLOW_WWW_USER_PASSWORD=12345
      - AIRFLOW__WEBSERVER__WARN_DEPLOYMENT_EXPOSURE=False
    env_file:
      - .env
      - .env.aws
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/scripts:/opt/airflow/scripts
      - ./airflow/utils:/opt/airflow/utils
      - ./dummy:/opt/airflow/dummy
    command: webserver

  # Airflow Scheduler
  airflow-scheduler:
    image: apache/airflow:2.8.1
    depends_on:
      - airflow-webserver
    environment:
      - PYTHONPATH=/opt/airflow
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:12345@airflow-db/airflow
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:12345@airflow-db/airflow
      - AIRFLOW__CELERY__BROKER_URL=redis://:@redis:6379/0
    env_file:
      - .env
      - .env.aws
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/scripts:/opt/airflow/scripts
      - ./airflow/utils:/opt/airflow/utils
      - ./dummy:/opt/airflow/dummy
    command: scheduler

  # Airflow Worker
  airflow-worker:
    image: apache/airflow:2.8.1
    depends_on:
      - airflow-scheduler
    environment:
      - PYTHONPATH=/opt/airflow
      - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:12345@airflow-db/airflow
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:12345@airflow-db/airflow
      - AIRFLOW__CELERY__BROKER_URL=redis://:@redis:6379/0
    env_file:
      - .env
      - .env.aws
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/scripts:/opt/airflow/scripts
      - ./airflow/utils:/opt/airflow/utils
      - ./dummy:/opt/airflow/dummy
    command: celery worker

volumes:
  fastapi_postgres_data:
  airflow_postgres_data: